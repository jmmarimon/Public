{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVQXC_dSs44_"
   },
   "source": [
    "# Face Classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2cBVwfds45L"
   },
   "source": [
    "## Setup/Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24885,
     "status": "ok",
     "timestamp": 1626814902427,
     "user": {
      "displayName": "Jacob Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjC-yKvzVTb1zobawVkaFHsEIBIEkxI9kqWZX7pzg=s64",
      "userId": "16407710070398725275"
     },
     "user_tz": 420
    },
    "id": "NfYu7R3us45L",
    "outputId": "0e4aacb4-3bde-4af6-b383-2a6f19524303"
   },
   "outputs": [],
   "source": [
    "# Run this cell and follow instructions to connect this notebook to Google Drive\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "except ImportError:\n",
    "    print(\"Not on google drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1626815083218,
     "user": {
      "displayName": "Jacob Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjC-yKvzVTb1zobawVkaFHsEIBIEkxI9kqWZX7pzg=s64",
      "userId": "16407710070398725275"
     },
     "user_tz": 420
    },
    "id": "YvVZOd0mvAB2",
    "outputId": "cb1bd3b9-ad81-4074-8398-b14b17f141c5"
   },
   "outputs": [],
   "source": [
    "# Change directories (\"cd\") to the folder containing your\n",
    "# notebook and data folder by replacing the filepath below\n",
    "%cd path/to/folder/in/google/drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Run this cell to download the data from Amazon AWS\n",
    "# TODO If needed, replace your the local Google Drive path (/content/drive/MyDrive/pa2b/) with a path that works for you \n",
    "\n",
    "!wget -P /content/drive/MyDrive/pa2b/ https://cmu-dele-leaderboard-us-east-2-003014019879.s3.us-east-2.amazonaws.com/colab/pa2b/data2pb.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Run this cell to unzip the data from Amazon AWS to your local Drive\n",
    "# TODO If needed, replace your the local Google Drive path (/content/drive/MyDrive/pa1b/data1pb.zip) with a path that works for you \n",
    "\n",
    "!unzip -u /content/drive/MyDrive/pa2b/data2pb.zip -d /content/drive/MyDrive/pa2b/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1626815198874,
     "user": {
      "displayName": "Jacob Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjC-yKvzVTb1zobawVkaFHsEIBIEkxI9kqWZX7pzg=s64",
      "userId": "16407710070398725275"
     },
     "user_tz": 420
    },
    "id": "Zqq0_ZBSs45H"
   },
   "outputs": [],
   "source": [
    "# Run this cell to import packages and enable autoreloading code from other imported files\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mv7pNwQl51uh"
   },
   "source": [
    "### Auto-detect if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQh4445Wtkfg"
   },
   "outputs": [],
   "source": [
    "# Run this cell to automatically detect if GPU is available.\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Datasets/DataLoaders "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgBtE_Jas45M"
   },
   "source": [
    "## Question 1.1: Initialize Training/Validation Datasets for Classification\n",
    "As discussed in section 5 of the writeup, load in the **training** and **validation** datasets for classification.\n",
    "\n",
    "You'll want to use the [ImageFolder](https://pytorch.org/vision/stable/datasets.html#torchvision.datasets.ImageFolder) object from `torchvision`. Read the documentation for it to figure out how to initialize it. You'll need the paths to the classification train/val folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxQMxHvQs45O"
   },
   "outputs": [],
   "source": [
    "# [Given] Method for transforming image data to a tensor, give this to ImageFolder\n",
    "transform = torchvision.transforms.ToTensor() # give this to the ImageFolder object\n",
    "\n",
    "# TODO: Initialize dataset objects for training and validation using ImageFolder from torchvision.\n",
    "classification_train_dataset = None\n",
    "classification_val_dataset = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "classification_train_dataset = torchvision.datasets.ImageFolder(\"data/classification_train\", transform=transform)\n",
    "classification_val_dataset = torchvision.datasets.ImageFolder(\"data/classification_val\", transform=transform)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.2: Initialize Classification DataLoaders\n",
    "Now that you have the datasets initialized, give each of them to a [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).\n",
    "\n",
    "**DataLoader Hyperparam Notes**\n",
    "\n",
    "Set the args for the `DataLoader` based on these notes. This assignment is really compute/memory intensive, so these will make a big difference in speeding up training.\n",
    "\n",
    "- `batch_size`\n",
    "    - See assignment 1b writeup for how to select `batch_size`.\n",
    "        - `64` is a decent starting number for the train dataset.\n",
    "    - Validation/test can have larger `batch_size`, this will speed up eval\n",
    "        - In general, we want to maximize val/test batch sizes because we just need to get through them quickly, and because it has no impact on training or the final accuracy score.\n",
    "        - We can do larger batch sizes training because we have more free memory available, because no gradients are stored during eval.\n",
    "- `pin_memory`\n",
    "    - Read this [page](https://pytorch.org/docs/stable/data.html#memory-pinning), set to `True`\n",
    "- `num_workers`\n",
    "    - Given below. We set to the number of CPU cores you have available.\n",
    "        - You can use this same value for train, val, and test.\n",
    "    - For what this does, read this [page](https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Given] How many \"workers\" (multi-processing parallel threads) each dataloader should have. \n",
    "num_workers = os.cpu_count()\n",
    "print(f\"num_workers (# cpu cores): {num_workers}\")\n",
    "\n",
    "# TODO: Initialize `Dataloader` objects.\n",
    "classification_train_dataloader = None\n",
    "classification_val_dataloader = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "batch_size = 64\n",
    "classification_train_dataloader = torch.utils.data.DataLoader(classification_train_dataset, batch_size=batch_size, pin_memory=True, shuffle=True, num_workers=num_workers)\n",
    "classification_val_dataloader = torch.utils.data.DataLoader(classification_val_dataset, batch_size=batch_size, pin_memory=True, shuffle=False, num_workers=num_workers)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.3: Initialize Val Verification Dataset/Dataloader\n",
    "\n",
    "We need this because, while training on classification, we also want to see how our model is doing on verification every epoch.\n",
    "\n",
    "We only initialize the validation set for now, because the test set is only needed at the very end of the assignment when you want to generate your submission for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import VerificationDataset \n",
    "\n",
    "# [Given] Custom dataset object for verification task. See utils.py for its implementation. \n",
    "verify_verification_dataset = VerificationDataset(\"data\", \"data/verification_pairs_val.txt\")\n",
    "\n",
    "# TODO: Initialize `Dataloader` object (similar to above question)\n",
    "verification_val_dataloader = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "batch_size = 64\n",
    "verification_val_dataloader = torch.utils.data.DataLoader(verify_verification_dataset, batch_size=batch_size, pin_memory=True, shuffle=False, num_workers=num_workers)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FW3-T-pMs45U"
   },
   "source": [
    "# Section 2: ResNet Model\n",
    "\n",
    "Now let's implement your model: ResNet.\n",
    "\n",
    "<!-- \n",
    "Note that our model is a class that extends `nn.Module`. Extending `nn.Module` means that any `nn.Module`s assigned as attributes to the class will automatically have their parameters absorbed. So when we do the following:\n",
    "\n",
    "    model = Model()\n",
    "    optimizer = MyOptimizer(model.parameters())\n",
    "\n",
    "Any attributes of `model` that have parameters will have those parameters included in `model.parameters()`, so `optimizer` will optimize them during training. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1: `ResBlock`\n",
    "\n",
    "<p align=\"center\"><img src=\"images/resblock_downsample_false.png\" width=\"400\"/><img src=\"images/resblock_downsample_true.png\" width=\"411\"/></p>\n",
    "\n",
    "Recall that ResNet is composed of these modular `ResBlock` units that are simply stacked together with differing parameters to get the final model.\n",
    "\n",
    "Also recall that the block differs depending on whether `downsample` is `False` or `True`.\n",
    "\n",
    "- If `downsample=False` (left-side of diagram), the output's width/height will end up unchanged from the input's.\n",
    "- If `downsample=True` (right-side of diagram), the output's width/height end up smaller than the input's.\n",
    "\n",
    "For both cases, the number of output channels depends solely on how you specify `out_channels`.\n",
    "\n",
    "<p align=\"center\"><img src=\"images/residual_sizes_downsample_false.png\" width=\"400\"/><img src=\"images/residual_sizes_downsample_true.png\" width=\"411\"/></p>\n",
    "\n",
    "The above diagram shows how to specify layer sizes for both the `downsample=False` case and the `downsample=True` case.\n",
    "\n",
    "Most important differences:\n",
    "\n",
    "- If `downsample=False`, the shortcut should be `nn.Identity()`, and the first `Conv1d` in `self.residual` should have `stride=1`.\n",
    "- If `downsample=True`, the shortcut should be the block shown on the bottom right, and the first `Conv1d` in `self.residual` should have `stride=2`.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "Implement `ResBlock.__init__()` and `ResBlock.forward()` below. The `# TODO` comments should walk you through what to implement.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, downsample=False):\n",
    "        super().__init__()            \n",
    "        # TODO: Initialize the residual EXCLUDING the last `ReLU`.\n",
    "        # Your stride for the first layer will need to depend on the `downsample` variable.\n",
    "        self.residual = nn.Sequential(\n",
    "            # Add appropriate layers here\n",
    "        )\n",
    "        \n",
    "        # TODO: Implement the shortcut (right side of diagram) based on whether or not `downsample` is True or False\n",
    "        if downsample:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                # Add appropriate layers here\n",
    "            ) \n",
    "        else:\n",
    "            # TODO: If no downsampling, use an Identity layer\n",
    "            self.shortcut = None\n",
    "        \n",
    "        # TODO: Implement the final ReLU activation function\n",
    "        self.final_activation = None\n",
    "        \n",
    "        ### BEGIN SOLUTION\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=2 if downsample else 1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "                \n",
    "        if downsample:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, 2),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "            \n",
    "        self.final_activation = nn.ReLU()\n",
    "        ### END SOLUTION\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: pass the input through the residual (don't overwrite `x`!)\n",
    "        residual_out = None\n",
    "\n",
    "        # TODO: pass the input through the shortcut\n",
    "        shortcut_out = None\n",
    "        \n",
    "        # TODO: add the shortcut and residual outputs, and pass them through the final activation\n",
    "        final_out = None\n",
    "        \n",
    "        ### BEGIN SOLUTION\n",
    "        shortcut_out = self.shortcut(x)\n",
    "        residual_out = self.residual(x)\n",
    "        final_out = self.final_activation(shortcut_out + residual_out)\n",
    "        ### END SOLUTION\n",
    "\n",
    "        return final_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2: `ResNet`\n",
    "\n",
    "Now we can implement the overall model.\n",
    "\n",
    "First, implement `ResNet.__init__()`. Begin by implementing the table with our recommended architecture from the writeup.\n",
    "\n",
    "You definitely can modify the widths/depths yourself later, but you'll need to carefully ensure the sizes will line up.\n",
    "\n",
    "Second, implement `ResNet.forward()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO: Implement the first Conv2d layer\n",
    "        self.conv = None\n",
    "        \n",
    "        # TODO: Implement a nn.Sequential containing the ResBlocks.\n",
    "        self.blocks = nn.Sequential(\n",
    "            # Add appropriate layers here, make sure to set downsample appropriately.\n",
    "        )\n",
    "        self.linear = None\n",
    "        ### BEGIN SOLUTION\n",
    "        self.conv = nn.Conv2d(3, 64, 3, 1, padding=1)\n",
    "        self.blocks = nn.Sequential(\n",
    "            ResBlock(64, 64, 3),\n",
    "            ResBlock(64, 64, 3),\n",
    "\n",
    "            ResBlock(64, 128, 3, True),\n",
    "            ResBlock(128, 128, 3),\n",
    "\n",
    "            ResBlock(128, 256, 3, True),\n",
    "            ResBlock(256, 256, 3),\n",
    "\n",
    "            ResBlock(256, 512, 3, True),\n",
    "            ResBlock(512, 512, 3),\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(512, 4000)\n",
    "        ### END SOLUTION\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Pass the input through the first convolution\n",
    "        conv_out = None\n",
    "        \n",
    "        # TODO: Pass conv_out through the ResBlocks\n",
    "        block_out = None\n",
    "        \n",
    "        # TODO: Average the output along the last two axes to get the embedding\n",
    "        features = None\n",
    "        \n",
    "        # TODO: Pass the features through the final linear layer\n",
    "        logits = None\n",
    "        \n",
    "        # this function should return (embedding, logits)\n",
    "        ### BEGIN SOLUTION\n",
    "        features = self.blocks(self.conv(x)).mean(2).mean(2)\n",
    "        logits = self.linear(features)\n",
    "        ### END SOLUTION\n",
    "        \n",
    "        # [Given] Return both the logits AND features; will need logits for classification, features for verification\n",
    "        return logits, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to initialize your model.\n",
    "\n",
    "If there are any errors/exceptions thrown during the initialization, you likely made a mistake during implementation somewhere. But even if there are no errors thrown, you could have still made a mistake! It'll become apparent when you run your training loop for the first time.\n",
    "\n",
    "This is a good opportunity to learn how to read the error messages and debug neural networks. Remember: the `%debug` Jupyter notebook command is really useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to initialize your model\n",
    "model = ResNet()\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# make sure the model initializes properly\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhQW0BG7s45P"
   },
   "source": [
    "# Section 3: Training/Validation/Prediction Routines\n",
    "\n",
    "Now to write the training/eval routines.\n",
    "\n",
    "Below, we've given you the overall `train()` method. It should look mostly familiar, but the main difference is that we do **two validations** every epoch:\n",
    "\n",
    "One validation on the **classification** task, and a second for the **verification** task.\n",
    "\n",
    "We do this to get a sense of how our model is doing for each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Given] ALREADY COMPLETED, SHOWN JUST FOR YOUR REFERENCE\n",
    "def train(model, optimizer, classification_train_dataloader, classification_val_dataloader,\n",
    "          verification_val_dataloader, num_epochs, scheduler=None, center_loss_function=None):\n",
    "    \"\"\"[Given] Trains and validates network for given number of epochs\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Your initialized ResNet model.\n",
    "        optimizer (optim.Optimizer): Initialized optimizer like `optim.SGD` or `optim.Adam`\n",
    "        classification_train_dataloader (torch.utils.data.DataLoader): Classification train dataloader\n",
    "        classification_val_dataloader (torch.utils.data.DataLoader): Classification val dataloader\n",
    "        verification_val_dataloader (torch.utils.data.DataLoader): Verification val dataloader\n",
    "        num_epochs (int): Number of epochs to train for\n",
    "        scheduler (optim.lr_scheduler): Initialized scheduler like `optim.lr_scheduler.ReduceLROnPlateau` (or None)\n",
    "    Returns:\n",
    "        (list, list): a list of loss values per batch and a list of validation accuracies every epoch\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        print(f\"Epoch #{e}\")\n",
    "        epoch_losses = train_epoch(model, optimizer, classification_train_dataloader, \\\n",
    "                                   scheduler, center_loss_function)\n",
    "        losses.extend(epoch_losses)\n",
    "        \n",
    "        # Eval on classification validation set\n",
    "        val_accuracy = eval_classification(model, classification_val_dataloader)\n",
    "        print(\"Classification Val Accuracy:\", 100 * val_accuracy)\n",
    "        \n",
    "        # Eval on verification validation set\n",
    "        verification_accuracy = eval_verification(model, verification_val_dataloader)\n",
    "        print(\"Verification Val ROC AUC:\", 100 * verification_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "\n",
    "    return losses, val_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also given below is the evaluation method for classification.  It's very similar to the previous assignments', so we figured we'd just give it to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pP-knU9ms45T"
   },
   "outputs": [],
   "source": [
    "# [Given] ALREADY COMPLETED, SHOWN JUST FOR YOUR REFERENCE\n",
    "def eval_classification(model, dataloader):\n",
    "    \"\"\"[Given] Evaluates network and calculates accuracy for a full validation dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Sequential): Your initialized network, stored in a `Sequential` object.\n",
    "        dataloader (torch.utils.data.DataLoader): Initialized validation dataloader\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy rate for entire val set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    # Run faster by ignoring information necessary for calculating gradients\n",
    "    with torch.no_grad():\n",
    "        for i, (data, labels) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "            # Put tensors on specified device\n",
    "            data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            # Get the two outputs of ResNet.forward()\n",
    "            logits, features = model(data) # Note that we don't need `features` so we just ignore it.\n",
    "            \n",
    "            # Get integer predictions by taking the max index along the `logits`. Then compare against the labels. \n",
    "            num_correct = (logits.argmax(axis=1) == labels).sum()\n",
    "            \n",
    "            total_correct += num_correct.item()\n",
    "\n",
    "    return total_correct / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1: `eval_verification()`\n",
    "\n",
    "Now you'll implement evaluation on the **verification** task.\n",
    "\n",
    "**Overview**\n",
    "\n",
    "Instead of calculating accuracy, this method calculates the [Area Under the Curve (AUC) of the ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve), which is a common metric for evaluating binary classifiers. Remember, this problem is binary classification: are these two images of the same person or not?\n",
    "\n",
    "To do this, we first need to calculate the predicted cosine similarity scores for each pair of images in the verification val set. Once we have those, we can calculate the AUC ROC and return it.\n",
    "\n",
    "**Methodology**\n",
    "- We iterate through the `verification_val_dataloader` to get our pairs of images.\n",
    "    - Each iteration, we get two batches of images. For example, if `batch_size=5`, we get two batches that each contain 5 images.\n",
    "    - We give the model each batch, one at a time. \n",
    "        - Doesn't matter which batch you provide first\n",
    "    - We grab the `feature` matrix the model outputs for each batch, and give them to our initialized `nn.CosineSimilarity` module\n",
    "    - This should return all of the cosine similarity scores for the batch. `extend` the given `similarities` list with these scores.\n",
    "- After calculating all of the cosine similarity scores, we give these and the true binary labels to `roc_auc_score` function\n",
    "    - The function is imported for you in the next cell\n",
    "- The output of `roc_auc_score` is a single float, representing your ROC AUC score for the entire verification val dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def eval_verification(model, verification_val_dataloader):\n",
    "    \"\"\"[Given] Evaluates network and calculates ROC AUC for a full validation dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Self-explanatory!\n",
    "        verification_val_dataloader (torch.utils.data.DataLoader): Initialized verification val dataloader\n",
    "\n",
    "    Returns:\n",
    "        float: ROC AUC for entire val set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # TODO: Initialize the nn.CosineSimilarity object from torch\n",
    "    cosine_similarity = None\n",
    "    ### BEGIN SOLUTION\n",
    "    cosine_similarity = nn.CosineSimilarity()\n",
    "    ### END SOLUTION\n",
    "\n",
    "    # [Given] Cosine similarity scores go here\n",
    "    similarities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (batch_1, batch_2, _) in tqdm(verification_val_dataloader, total=len(verification_val_dataloader)):\n",
    "            # [Given] Put batches on GPU\n",
    "            batch_1, batch_2 = batch_1.to(DEVICE), batch_2.to(DEVICE)\n",
    "\n",
    "            # TODO: Give each batch to the model, store the feature output of each\n",
    "            ### BEGIN SOLUTION\n",
    "            _, features_1 = model(batch_1)\n",
    "            _, features_2 = model(batch_2)\n",
    "            ### END SOLUTION\n",
    "\n",
    "            # TODO: Give the feature vectors to cosine_similarity, get the scores\n",
    "            batch_similarities = None\n",
    "            ### BEGIN SOLUTION\n",
    "            batch_similarities = cosine_similarity(features_1, features_2)\n",
    "            ### END SOLUTION\n",
    "\n",
    "            # [Given] Store the similarity scores\n",
    "            similarities.extend(batch_similarities.tolist())\n",
    "\n",
    "    # [Given] List of binary labels for the entire dataset\n",
    "    labels = verification_val_dataloader.dataset.get_labels()\n",
    "\n",
    "    # TODO: Give the labels and the similarities to the roc_auc_score function, return the final score\n",
    "    auc_score = None\n",
    "    ### BEGIN SOLUTION\n",
    "    auc_score = roc_auc_score(labels, similarities)\n",
    "    ### END SOLUTION\n",
    "\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aW5b7K4s45Q"
   },
   "source": [
    "## Question 3.2: `train_epoch()`\n",
    "\n",
    "Now to write the training routine of a single epoch.\n",
    "\n",
    "**Note: If you haven't already, read section 6 of the writeup for explanations of mixed precision and center loss.**\n",
    "\n",
    "The pseudocode below reflects the usage of both techniques. Note that we're giving you parts of this because it's pretty complicated and the main point of this exercise is the concepts.\n",
    "\n",
    "```\n",
    "def train_epoch():\n",
    "    set_model_to_train_mode()\n",
    "    alpha = 0.005\n",
    "    grad_scaler = create_amp_gradient_scaler()\n",
    "    for (data, labels) in tqdm(dataloader):\n",
    "        data, labels = put_tensors_on_appropriate_device(DEVICE, data, labels) # See val method for how to do this\n",
    "        reset_gradients_to_zero()\n",
    "        with autocast:\n",
    "            logits, features = forward_pass_through_model(model, data)\n",
    "            center_loss = center_loss_function(features, labels) * alpha\n",
    "            loss = cross_entropy_loss_function(logits, labels) + center_loss\n",
    "        backprop_with_amp_scaled_gradients() \n",
    "        update_center_loss_params()\n",
    "        update_model_with_amp_scaled_gradients()\n",
    "        update_scaler()\n",
    "        store_loss_value(loss)\n",
    "\n",
    "    return loss_values\n",
    "```\n",
    "\n",
    "**CenterLoss Notes:**\n",
    "- We're using the \"second method\" described in the [readme](https://github.com/KaiyangZhou/pytorch-center-loss), with one optimizer for model and loss function parameters.\n",
    "- Notice that `CenterLoss` has **trainable parameters**\n",
    "    - If you rerun training, you should make sure to use the same object without reinitializing it. If you initialize it again, it'll lose the centers it was training.\n",
    "- We're using `alpha=0.005` for center loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pN7m5dlRs45R"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, dataloader, scheduler=None, center_loss_function=None):\n",
    "    \"\"\"Train model for one epoch.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Initialized ResNet network.\n",
    "        optimizer (optim.Optimizer): Initialized optimizer like `optim.SGD` or `optim.Adam`\n",
    "        dataloader (torch.utils.data.DataLoader): Initialized training dataloader\n",
    "        center_loss_function (CenterLoss): Initialized CenterLoss object (imported from `center_loss.py`).\n",
    "        scheduler (optim.lr_scheduler): Optional scheduler if you want it\n",
    "\n",
    "    Returns:\n",
    "        list: Loss value of each batch for this epoch.\n",
    "    \"\"\"\n",
    "    # [Given] Make sure you're aware of what's here\n",
    "    loss_per_batch = []\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    alpha = 0.005\n",
    "\n",
    "    # TODO: set model to train mode\n",
    "        \n",
    "    # TODO: initialize your AMP gradient scaler \n",
    "    amp_grad_scaler = None\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    model.train()\n",
    "    amp_grad_scaler = torch.cuda.amp.GradScaler()\n",
    "    ### END SOLUTION\n",
    "\n",
    "    # Run loop with `tqdm` progress bar\n",
    "    for i, (data, labels) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        # TODO: Complete code based on pseudocode\n",
    "        ### BEGIN SOLUTION\n",
    "        data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            logits, features = model(data)\n",
    "            center_loss = center_loss_function(features, labels) * alpha\n",
    "            loss = loss_function(logits, labels) + center_loss\n",
    "        ### END SOLUTION\n",
    "        \n",
    "        # [Given] Run backprop on scaled gradient with AMP\n",
    "        amp_grad_scaler.scale(loss).backward()\n",
    "        \n",
    "        # [Given] Manually update center loss trainable parameters\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        for param in center_loss_function.parameters():\n",
    "            param.grad.data *= (1e-1 /(alpha * lr))\n",
    "\n",
    "        # [Given] Update model parameters (equivalent to doing `optimizer.step()` without AMP)\n",
    "        amp_grad_scaler.step(optimizer)\n",
    "        amp_grad_scaler.update()\n",
    "\n",
    "        # [Given] Store the loss value for the batch\n",
    "        loss_per_batch.append(loss.item())\n",
    "\n",
    "    # TODO (Optional): step the scheduler if it is not None\n",
    "    ### BEGIN SOLUTION\n",
    "    if scheduler is not None:\n",
    "        scheduler.step(sum(loss_per_batch))\n",
    "    ### END SOLUTION\n",
    "    return loss_per_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Train Model!\n",
    "\n",
    "Almost there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.1: Initialize objects\n",
    "\n",
    "Time to initialize objects. If things break, you may need to figure out what the error messages mean and backtrack to fix the appropriate thing.\n",
    "\n",
    "Google is your friend. Post questions if you're particularly lost.\n",
    "\n",
    "Here's a link to the [CenterLoss documentation](https://github.com/KaiyangZhou/pytorch-center-loss), and a description of [LR schedulers](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate). A good scheduler is ReduceLROnPlateau.\n",
    "\n",
    "Note that instead of using an optimizer for center loss, and a different one for the model as suggested in the center loss docsm, we can turn both parameter sets into lists, and then concatenate them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from center_loss import CenterLoss\n",
    "\n",
    "# Note: you already should have initialized your model a few cells above, but you can reinitialize it here if you want.\n",
    "\n",
    "# TODO: Initialize center loss function (see the readme and/or center_loss.py)\n",
    "center_loss_function = None\n",
    "\n",
    "# TODO: Concatenate your model and center loss function parameters so that you can just use one optimizer;\n",
    "#       this will looks like list(model.parameters()) + list(center_loss_function.parameters())\n",
    "parameters = None\n",
    "\n",
    "# TODO: Initialize optimizer with combined parameters.\n",
    "optimizer = None\n",
    "\n",
    "# TODO: (Optional) Initialize a scheduler if you want it!\n",
    "scheduler = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "center_loss_function = CenterLoss(num_classes=4000, feat_dim=512, device=DEVICE)\n",
    "parameters = list(model.parameters()) + list(center_loss_function.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=0)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.2: Run training!\n",
    "\n",
    "Now to run training! Begin by training for 8 epochs and see how it does. We encourage you to generate test results for section 5 as soon and as often as possible, so you can guarantee you'll at least earn some points before the final deadline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Call your training routine for some epochs\n",
    "num_epochs = 8\n",
    "# losses, val_accuracies = train() # TODO: Finish me!\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "losses, val_accuracies = train(model, optimizer, classification_train_dataloader, \\\n",
    "                               classification_val_dataloader, verification_val_dataloader, \\\n",
    "                               num_epochs, scheduler, center_loss_function)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITPLwKKzs45X"
   },
   "source": [
    "# Section 5: Generating Test Predictions for Submitting!\n",
    "\n",
    "Now to submit! Run these cells below and look for the output file generated in the `submissions/` folder (it will be time-stamped).\n",
    "\n",
    "**NOTE:** The first two rows of the CSV should look like this:\n",
    "\n",
    "`Id,Category\n",
    "verification_data/00020839.jpg verification_data/00035322.jpg,[some number]`\n",
    "\n",
    "**Please remember to edit the second entry of the first row ('Category') to the name you want to appear on the leaderboard.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oo2bEmc9s45Y"
   },
   "outputs": [],
   "source": [
    "from utils import export_predictions_to_csv, generate_predictions\n",
    "\n",
    "test_verification_dataset = VerificationDataset(\"./data/\", \"./data/verification_pairs_test.txt\", True)\n",
    "test_verification_dataloader = torch.utils.data.DataLoader(test_verification_dataset, batch_size=batch_size,\n",
    "                                                           pin_memory=True, shuffle=False,\n",
    "                                                           num_workers = num_workers)\n",
    "similarities = generate_predictions(model, test_verification_dataloader, DEVICE)\n",
    "export_predictions_to_csv(\"data/verification_pairs_test.txt\", similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-2cBVwfds45L",
    "6ORcUUwWvZOu",
    "6kP0mE8gs45G",
    "mv7pNwQl51uh"
   ],
   "name": "pa_01_B_assignment.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "c79f8f21da264bd1d028db25c6791996e084443b727ae68f20d92653727834ef"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
